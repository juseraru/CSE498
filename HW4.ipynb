{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4e1cd4",
   "metadata": {},
   "source": [
    "# GRID WORLD MultiAgent\n",
    "\n",
    "### first the simple single agent with policy interation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca4d5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 2., 2., 2.],\n",
       "       [1., 1., 1., 0., 3.],\n",
       "       [1., 1., 0., 0., 3.],\n",
       "       [1., 0., 0., 0., 3.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "WS = 5\n",
    "\n",
    "# right, up, left, down\n",
    "#  0     1     2     3\n",
    "A = [np.array([0, 1]),\n",
    "     np.array([-1, 0]),\n",
    "     np.array([0, -1]),\n",
    "     np.array([1, 0])]\n",
    "\n",
    "AP = 0.25\n",
    "\n",
    "def is_terminal(state):\n",
    "    x, y = state\n",
    "    return (x == 0 and y == 0) or (x == WS - 1 and y == WS - 1)\n",
    "\n",
    "def step(state, action):\n",
    "    if is_terminal(state):\n",
    "        return state, 0\n",
    "\n",
    "    next_state = state + action\n",
    "    x, y = next_state\n",
    "\n",
    "    if x < 0 or x >= WS or y < 0 or y >= WS:\n",
    "        # if agent gets to wall stays in same cell\n",
    "        next_state = state\n",
    "\n",
    "    reward = -1\n",
    "    return next_state, reward\n",
    "\n",
    "\n",
    "values = np.zeros((WS,WS))\n",
    "theta = 1e-6\n",
    "disc = 1\n",
    "\n",
    "def valueEvaluation(values, qs, disc, theta, A=A, WS = WS):\n",
    "    new_v = np.zeros_like(values)\n",
    "    while True:\n",
    "        delta = 0\n",
    "        ### i j to walk through all states once.\n",
    "        for i in range(WS):\n",
    "            for j in range(WS):\n",
    "                v = 0\n",
    "                a = int(qs[i,j])\n",
    "                state = np.array([i,j])\n",
    "                n_state, reward = step(state,A[a])\n",
    "                new_v[i,j] = AP * (reward + disc*values[n_state[0],n_state[1]])    \n",
    "        delta = abs(values - new_v).max()\n",
    "        values = np.copy(new_v)\n",
    "        #print(delta)\n",
    "        if delta < theta:\n",
    "            return values\n",
    "    \n",
    "\n",
    "def policyIteration(values, qs, disc, theta, A=A, WS = WS):\n",
    "    stable = False\n",
    "    q = np.zeros_like(qs)\n",
    "    while not stable:\n",
    "        v = valueEvaluation(values,q,disc,theta, A, WS)\n",
    "        #print('values',v)\n",
    "        for i in range(WS):\n",
    "                for j in range(WS):\n",
    "                    best_a_in_s = np.zeros(len(A))\n",
    "                    state = np.array([i,j])\n",
    "                    for ai, a in enumerate(A):\n",
    "                        n_state, reward = step(state,a)\n",
    "                        d = disc*v[n_state[0],n_state[1]]\n",
    "                        #print(reward, d)\n",
    "                        best_a_in_s[ai] = reward + d\n",
    "                    #print('v in s',best_a_in_s)\n",
    "                    q[i,j] = np.argmax(best_a_in_s)\n",
    "        #print('q',q)\n",
    "        prepo = abs(q-qs)<theta\n",
    "        #print(prepo)\n",
    "        if np.all(prepo): \n",
    "            stable = True\n",
    "        qs = np.copy(q)\n",
    "    return qs\n",
    "\n",
    "qs = np.zeros((WS,WS)) #np.random.randint(0,4,(WS,WS))\n",
    "\n",
    "policyIteration(values, qs, disc, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0860fd",
   "metadata": {},
   "source": [
    "# gym-gridMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8874edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MAGridWorldEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, size=5, n_agents=1):\n",
    "        self.size = size  # The size of the square grid\n",
    "        self.window_size = 512  # The size of the PyGame window\n",
    "\n",
    "        # Observations are dictionaries with the agent's and the target's location.\n",
    "        # Each location is encoded as an element of {0, ..., `size`}^2, i.e. MultiDiscrete([size, size]).\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                \"agent\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "                \"target\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "            }\n",
    "        )\n",
    "        self.number_agents = n_agents\n",
    "        # We have 4 actions, corresponding to \"right\", \"up\", \"left\", \"down\"\n",
    "        if self.number_agents == 1:\n",
    "            self.action_space = spaces.Discrete(5)\n",
    "        else:\n",
    "            self.action_space = [spaces.Discrete(5) for _ in range(self.number_agents)]\n",
    "           \n",
    "        self._target_location = [np.array([0,0]),np.array([size-1,size-1])]\n",
    "\n",
    "        \"\"\"\n",
    "        The following dictionary maps abstract actions from `self.action_space` to \n",
    "        the direction we will walk in if that action is taken.\n",
    "        I.e. 0 corresponds to \"right\", 1 to \"up\" etc.\n",
    "        \"\"\"\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([1, 0]),\n",
    "            1: np.array([0, 1]),\n",
    "            2: np.array([-1, 0]),\n",
    "            3: np.array([0, -1]),\n",
    "            4: np.array([0, 0]),\n",
    "        }\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        \"\"\"\n",
    "        If human-rendering is used, `self.window` will be a reference\n",
    "        to the window that we draw to. `self.clock` will be a clock that is used\n",
    "        to ensure that the environment is rendered at the correct framerate in\n",
    "        human-mode. They will remain `None` until human-mode is used for the\n",
    "        first time.\n",
    "        \"\"\"\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        \n",
    "    def _get_obs(self):\n",
    "        return self._agent_location\n",
    "\n",
    "    def check(self, temp):\n",
    "        for i in range(len(self._target_location)):\n",
    "            if np.array_equal(temp, self._target_location[i]):\n",
    "                return True\n",
    "        for i in range(len(self._agent_location)):\n",
    "            if np.array_equal(temp, self._agent_location[i]):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        # We need the following line to seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        \n",
    "        # Choose the agent's location uniformly at random\n",
    "        if self.number_agents==1:\n",
    "            self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "        else:\n",
    "            self._agent_location = []\n",
    "            for _ in range(self.number_agents):\n",
    "                temp = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "                while self.check(temp):\n",
    "                    temp = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "                self._agent_location.append(temp)\n",
    "            \n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def step(self, action, state = None,flag=False):\n",
    "        # Map the action (element of {0,1,2,3}) to the direction we walk in\n",
    "        if self.number_agents == 1:\n",
    "            direction = self._action_to_direction[action]\n",
    "        else:\n",
    "            direction = []\n",
    "            for n in range(self.number_agents):\n",
    "                direction.append(self._action_to_direction[action[n]])\n",
    "                \n",
    "        # We use `np.clip` to make sure we don't leave the grid\n",
    "        if state is None:    \n",
    "            if self.number_agents == 1:\n",
    "                self._agent_location = np.clip(\n",
    "                    self._agent_location + direction, 0, self.size - 1\n",
    "                )\n",
    "            else:\n",
    "                self._agent_location = [l for l in np.clip(\n",
    "                    np.array(self._agent_location) + np.array(direction), 0, self.size - 1\n",
    "                )]\n",
    "        else:\n",
    "            if self.number_agents == 1:\n",
    "                self._agent_location = np.clip(\n",
    "                    state + direction, 0, self.size - 1\n",
    "                )\n",
    "            else:\n",
    "                self._agent_location = [l for l in np.clip(\n",
    "                    state.reshape(-1,2) + np.array(direction), 0, self.size - 1\n",
    "                )]\n",
    "                           \n",
    "        # An episode is done iff the agent has reached the target\n",
    "        if self.number_agents == 1:\n",
    "            terminated = np.array_equal(self._agent_location, self._target_location[0]) \\\n",
    "                        or np.array_equal(self._agent_location, self._target_location[1]) \n",
    "            reward = 1 if terminated else 0  # Binary sparse rewards\n",
    "            observation = self._get_obs()\n",
    "        else:\n",
    "            terminated = []\n",
    "            for n in range(self.number_agents):\n",
    "                t = np.array_equal(self._agent_location[n], self._target_location[0]) \\\n",
    "                    or np.array_equal(self._agent_location[n], self._target_location[1]) \n",
    "                terminated.append(t)\n",
    "            observation = self._get_obs()\n",
    "            \n",
    "            # check for collisions which will produce bad reward\n",
    "            reward = -1\n",
    "            for c in itertools.combinations(range(self.number_agents),2):\n",
    "                if np.array_equal(self._agent_location[c[0]],self._agent_location[c[1]]):\n",
    "                    if np.any([np.array_equal(self._agent_location[c[0]],x) for x in self._target_location]):\n",
    "                        continue \n",
    "                    reward += -3\n",
    "                    \n",
    "            reward = 0 if np.all(np.array(terminated)) else reward\n",
    "            terminated = np.all(np.array(terminated))\n",
    "        \n",
    "        if self.render_mode == \"human\" and flag:\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, reward, terminated\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "        if self.clock is None and self.render_mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        pix_square_size = (\n",
    "            self.window_size / self.size\n",
    "        )  # The size of a single grid square in pixels\n",
    "\n",
    "        # First we draw the target\n",
    "        pygame.draw.rect(\n",
    "            canvas,\n",
    "            (255, 0, 0),\n",
    "            pygame.Rect(\n",
    "                pix_square_size * self._target_location[0],\n",
    "                (pix_square_size, pix_square_size),\n",
    "            ),\n",
    "        )\n",
    "        pygame.draw.rect(\n",
    "            canvas,\n",
    "            (255, 0, 0),\n",
    "            pygame.Rect(\n",
    "                pix_square_size * self._target_location[1],\n",
    "                (pix_square_size, pix_square_size),\n",
    "            ),\n",
    "        )\n",
    "        # Now we draw the agent\n",
    "        if self.number_agents == 1:\n",
    "            pygame.draw.circle(\n",
    "                canvas,\n",
    "                (0, 0, 255),\n",
    "                (self._agent_location + 0.5) * pix_square_size,\n",
    "                pix_square_size / 3,\n",
    "            )\n",
    "        else:\n",
    "            for n in range(self.number_agents):\n",
    "                pygame.draw.circle(\n",
    "                canvas,\n",
    "                (0, 0, 255),\n",
    "                (self._agent_location[n] + 0.5) * pix_square_size,\n",
    "                pix_square_size / 3,\n",
    "            )\n",
    "            \n",
    "\n",
    "        # Finally, add some gridlines\n",
    "        for x in range(self.size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (0, pix_square_size * x),\n",
    "                (self.window_size, pix_square_size * x),\n",
    "                width=3,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (pix_square_size * x, 0),\n",
    "                (pix_square_size * x, self.window_size),\n",
    "                width=3,\n",
    "            )\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # We need to ensure that human-rendering occurs at the predefined framerate.\n",
    "            # The following line will automatically add a delay to keep the framerate stable.\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "501ffe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4, 3]), array([2, 1])]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 2 #robots\n",
    "m = 5 # size of grid\n",
    "grid = MAGridWorldEnv(size=m, n_agents=n,render_mode=\"rgb_array\")\n",
    "\n",
    "grid.reset(0)\n",
    "#time.sleep(5)\n",
    "#grid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "4893879b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(grid.render())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "d3ac659e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([3, 3]), array([3, 1])], -1, False)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.step(action=[2,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "52e1566d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(grid.render())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "ccd95e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 1]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(grid._agent_location).flatten().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060214ca",
   "metadata": {},
   "source": [
    "# Value Iteration with Greedy policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "98c3ccdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625, 4)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### state space, is a permutation with replacement\n",
    "### of m elements with 2*n dimention. \"cartesian product\"\n",
    "\n",
    "z = np.array(list(itertools.product(np.arange(m), repeat=2*n)))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "3d10a346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625, 4)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### another way to obtain the state space\n",
    "x = [np.arange(m)]*(2*n)\n",
    "y = np.array(np.meshgrid(*x)).T.reshape(-1,2*n)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "63cfc9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### actions\n",
    "a = np.array(list(itertools.product(np.arange(len(grid._action_to_direction)), repeat=n)))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "78e72d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 4, 1, 0]), -0.5636225736540552)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension = [m]*2*n\n",
    "v = np.random.randn(*dimension)\n",
    "\n",
    "y[34,:],v[tuple(np.vstack(y[34,:]).flatten())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "5602c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valueIteration_gridMA(env, size=3, n_agents=2, action=5, disc=0.5, epoch=10, theta=None, values = None):\n",
    "    env.render_mode = None\n",
    "    if values is None:\n",
    "        dimension = [size]*2*n_agents\n",
    "        v = np.zeros((dimension))\n",
    "    else:\n",
    "        v = values\n",
    "    states = np.array(list(itertools.product(np.arange(size), repeat=2*n_agents)))\n",
    "    actions = np.array(list(itertools.product(np.arange(action), repeat=n_agents)))\n",
    "    ap = 1/len(actions)\n",
    "    for i in range(epoch):\n",
    "        for s in states:\n",
    "            temp = np.zeros(actions.shape[0]) \n",
    "            for k,a in enumerate(actions):\n",
    "                n_state, reward, ter = env.step(a,s)\n",
    "                if ter:\n",
    "                    temp[k] = 0\n",
    "                else:\n",
    "                    temp[k] = ap * (reward + disc*v[tuple(np.vstack(n_state).flatten())]) \n",
    "            v[tuple(np.vstack(s).flatten())] = np.sum(temp)\n",
    "        print(i, end=' ')\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "2ace4063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 "
     ]
    }
   ],
   "source": [
    "values = valueIteration_gridMA(grid,m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "712ed362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(env, policy, actions):\n",
    "    env.render_mode = \"human\"\n",
    "    T = 30 ### number of steps in one episode\n",
    "    state = env.reset()\n",
    "    for t in range(T):\n",
    "        best = np.zeros(actions.shape[0])\n",
    "        for k,a in enumerate(actions):\n",
    "            n_state, reward, _ = env.step(a,np.array(state))\n",
    "            best[k] = policy[tuple(np.vstack(n_state).flatten())]\n",
    "        act = np.argmax(best)\n",
    "        state, _, ter = env.step(actions[act],np.array(state), True)\n",
    "        if ter:\n",
    "            break\n",
    "    env.close()\n",
    "\n",
    "simulation(grid,values,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f24c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
